# Mapeo de lecturas y llamado de variantes

## 1. Mapeo de lecturas
El sustrato para los estudios genómico-poblacionales son las variantes genéticas a lo largo del genoma en varios individuos de una o más poblaciones. Una vez que tenemos datos de secuenciación de alta calidad, el siguiente paso es mapear las lecturas a un genoma de referencia. Este proceso incluye varios pasos intermedios, como el control de calidad y filtrado de las lecturas y alineamientos.  
Primero creamos la carpeta de trabajo y copiamos el material:
```bash
mkdir 3-mapeo_variantes
cd 3-mapeo_variantes
cp /home/course/course2026/course_files/3-mapeo_variantes/* .
```
Usaremos un script para mapear lecturas pareadas a un genoma de referencia `1-mapeo.sh`.
```bash
cp /data/courses/course2026/course_files/scripts/1-mapeo.sh .
```
En el contenido cambiar los USERNAME a los nombres de grupo:
```bash
#!/bin/bash

# Nombre del proceso:
#SBATCH --job-name=1-mapeo

# Proyecto:
#SBATCH --account=tipo-iii
#SBATCH --partition=standard # Nombre de la partición

# Recursos:
#SBATCH --time=24:00:00 # Límite de tiempo de corrida
#SBATCH --cpus-per-task=15 # Límite de CPUs para cada tarea en tareas de múltiples instancias
#SBATCH --mem=25G # Límite de memoria

# Archivos de salida
#SBATCH --output=/data/courses/course2026/USERNAME/logs/mapeo_o%j # Nombre del archivo de salida stdout
#SBATCH --error=/data/courses/course2026/USERNAME/logs/mapeo_e%j # Nombre del archivo de error stderr

# Ambiente de trabajo
set -o errexit
set -o nounset

module --quiet purge
module load bwa
module load bowtie2
module load samtools
module list

# Mensaje informativo
echo "Tarea ${SLURM_JOB_NAME} iniciado en:"
date
echo "Nodo:"
hostname

# Comandos a ejecutar
ref_genome="/data/courses/course2026/course_files/mapeo_variantes/ppa_v2.asm.fasta"
reads_1="/data/courses/course2026/course_files/mapeo_variantes/Alg34_R1.fastq.gz"
reads_2="/data/courses/course2026/course_files/mapeo_variantes/Alg34_R2.fastq.gz"
suffix=$(basename $ref_genome .fasta)

#bwa mem -t 14 $ref_genome $reads_1 $reads_2 \
bowtie2 -p 14 -x $ref_genome -1 $reads_1 -2 $reads_2 \
| samtools view -h -b -q 30 \
| samtools sort -o ${SLURM_JOB_ID}.FIELD_LAM34.$suffix.bam

echo "Job finalizado en:"
date
```
El script usa el algoritmo de alineamiento mem para alinear lecturas según su similitud, luego usando samtools se filtran alineamientos con un mínimo de calidad (MAPQ) de 30 (0.999 de probabilidad de un match correcto) y se ordenan según las coordenadas en el cromosoma.  
```bash
sbatch 1-mapeo.sh
cat logs/mapeo_o
cat logs/mapeo_e
```
El resultado se guardó en formato binario `bam`, lo inspeccionamos de la siguiente manera:
```bash
module load samtools
samtools view -S FIELD_LAM34.bam | less -S
```
![image](https://samformat.pages.dev/images/sam_format_annotated_example.5108a0cd.jpg)
La información de alineamiento de cada lectura se resume en un decimal FLAG, los cuales pueden entenderse [aquí](https://samformat.pages.dev/sam-format-flag). También podemos obtener un resumen global usando:
```bash
samtools flagstat FIELD_LAM34.bam
```
La columna CIGAR (Concise Idiosyncratic Gapped Alignment Report), es una manera comprimida de representar las características del alineamiento de cada lectura, desde la primera posición de izquierda a derecha. Se mostrará en una sola línea los match (M), mismatch (X), deleciones (D) e inserciones (I).  
Algunos parámetros importantes para evaluar el éxito de alineamiento son:  
- Número de alineamientos en total
- Número de alineamientos únicos
- Fracción de lecturas mapeadas con respecto al total
- Porcentaje de duplicidad de lecturas

### Deduplicación de lecturas
Es recomendable detectar y eliminar los duplicados de lecturas, lo cual puede hacerse después del mapeo al genoma de referencia. En este tutorial usaremos el script `2-duplicados.sh`.
```bash
cp /data/courses/course2026/course_files/scripts/2-duplicados.sh .
```
En el contenido cambiar los USERNAME a los nombres de grupo, y agregarle el número de tarea correcto al input (NNN):
```bash
#!/bin/bash

# Nombre del proceso:
#SBATCH --job-name=2-dedup

# Proyecto:
#SBATCH --account=tipo-iii
#SBATCH --partition=standard # Nombre de la partición

# Recursos:
#SBATCH --time=24:00:00 # Límite de tiempo de corrida
#SBATCH --cpus-per-task=15 # Límite de CPUs para cada tarea en tareas de múltiples instancias
#SBATCH --mem=25G # Límite de memoria

# Archivos de salida
#SBATCH --output=/data/courses/course2026/USERNAME/logs/dedup_o%j # Nombre del archivo de salida stdout
#SBATCH --error=/data/courses/course2026/USERNAME/logs/dedup_e%j # Nombre del archivo de error stderr

# Ambiente de trabajo
set -o errexit
set -o nounset

module load samtools
module load picard
module list

# Mensaje informativo
echo "Tarea ${SLURM_JOB_NAME} iniciado en:"
date
echo "Nodo:"
hostname

# Comandos a ejecutar
input="NNN.FIELD_LAM34.ppa_v2.asm.bam"

samtools addreplacerg -r "@RG\tID:FIELD_LAM34\tSM:FIELD34\tPL:Illumina\tLB:FIELD_LAM34.fastq.gz" -o ${input%bam}addrg.bam $input
picard MarkDuplicates I=${input%bam}addrg.bam O=${SLURM_JOB_ID}.${input%bam}dedup.bam M=${SLURM_JOB_ID}.${input%bam}dedup.metrics REMOVE_DUPLICATES=true

echo "Job finalizado en:"
date
```
Someter la tarea al organizador:
```bash
sbatch 2-duplicados.sh
```
Revisar los resultados:
```bash
sed -n '7,8p' FIELD_LAM34.ppa_v2.asm.dedup.metrics | column -t | less -S
```
> [!IMPORTANT]
> :exclamation: Según las métricas, ¿cuál es el porcentaje de duplicidad de la muestra FIELD_LAM34?

```bash
samtools flagstat FIELD_LAM34.dedup.bam
```
> [!IMPORTANT]
> :question: ¿Qué diferencias hay en las estadísticas de alineamiento con respecto al archivo original?  
> :question: Intentemos el mismo procedimiento para la muestra HUSM25. ¿Cómo difieren los resultados de mapeo y duplicidad?  
> :question: ¿Qué resultados esperaríamos si en lugar del genoma nuclear, mapeamos las lecturas al genoma cloroplastidial?

### Profundidad y cobertura de mapeo
La profundidad es el número promedio de lecturas que cubren una posición en la secuencia de referencia. En cambio, la cobertura es el porcentaje de la secuencia de referencia secuenciada por lecturas a una determinada profundidad.

![image](https://i.sstatic.net/hZqvF.png)

Evaluamos la profundidad y amplitud de cobertura usando el script `3-cobertura.sh`.
```bash
cp /data/courses/course2026/course_files/scripts/3-cobertura.sh .
```
 En el contenido cambiar los USERNAME a los nombres de grupo y cambiar al número correcto de tarea (NNN.NNN):
```bash
#!/bin/bash

# Nombre del proceso:
#SBATCH --job-name=3-coverage

# Proyecto:
#SBATCH --account=tipo-iii
#SBATCH --partition=standard # Nombre de la partición

# Recursos:
#SBATCH --time=24:00:00 # Límite de tiempo de corrida
#SBATCH --cpus-per-task=15 # Límite de CPUs para cada tarea en tareas de múltiples instancias
#SBATCH --mem=25G # Límite de memoria

# Archivos de salida
#SBATCH --output=/data/courses/course2026/USERNAME/logs/coverage_o%j # Nombre del archivo de salida stdout
#SBATCH --error=/data/courses/course2026/USERNAME/logs/coverage_e%j # Nombre del archivo de error stderr

# Ambiente de trabajo
set -o errexit
set -o nounset

module --quiet purge
module load samtools
module list

# Mensaje informativo
echo "Tarea ${SLURM_JOB_NAME} iniciado en:"
date
echo "Nodo:"
hostname

# Comandos a ejecutar
input="NNN.NNN.FIELD_LAM34.ppa_v2.asm.dedup.bam"
genome_size=403689856
samtools depth $input > ${SLURM_JOB_ID}.${input%bam}depths
cut -f3 ${SLURM_JOB_ID}.${input%bam}depths | sort | uniq -c | tr -s ' ' | sed 's/^ //' | sed 's/ /\t/' | awk '{print $2 "\t" $1}' | sort -n > ${SLURM_JOB_ID}.${input%bam}histdepths
awk '{sum += $3} END {print sum/NR}' ${SLURM_JOB_ID}.${input%bam}depths > ${SLURM_JOB_ID}.${input%bam}averagedepth
awk '$3 >= 1' ${SLURM_JOB_ID}.${input%bam}depths | wc -l | awk -v genome_size="$genome_size" '{print $1/genome_size * 100}' > ${SLURM_JOB_ID}.${input%bam}breadthdepth
awk '$3 >= 10' ${SLURM_JOB_ID}.${input%bam}depths | wc -l | awk -v genome_size="$genome_size" '{print $1/genome_size * 100}' > ${SLURM_JOB_ID}.${input%bam}breadthdepthmin10

echo "Job finalizado en:"
date
```
Sometemos el script mediante el organizador slurm:
```bash
sbatch 3-cobertura.sh
```
Obtenemos la profundidad promedio y el porcentaje de la secuencia de referencia que es cubierto por al menos una lectura:
```bash
cat FIELD_LAM34.ppa_v2.asm.dedup.depths
cat FIELD_LAM34.ppa_v2.asm.dedup.breadthdepth
```
> [!IMPORTANT]
> :exclamation: ¿Cuál es la profundidad promedio? ¿Cuánto del genoma aproximadamente se ha secuenciado y mapeado exitosamente?  
> :exclamation: ¿Por qué la cobertura no es del 100%?

Notar que la profundidad se distribuye heterogéneamente a lo largo de la secuencia de referencia.
```bash
less -S FIELD_LAM34.ppa_v2.asm.dedup.histdepths
```
Por lo tanto, la amplitud de cobertura con una profundidad considerable es diferente:
```bash
cat FIELD_LAM34.ppa_v2.asm.dedup.breadthdepthmin10
```
> [!IMPORTANT]
> :exclamation: ¿Cuánto del genoma se cubre por al menos 10 lecturas por sitio? Intentar con 20X, 30X y con la profundidad promedio.

> [!IMPORTANT]
> :question: Intentemos el mismo procedimiento para la muestra HUSM25. ¿Cuánto de profundidad y amplitud de cobertura se alcanzó para esta muestra?  
> :question: ¿Qué esperaríamos para la profundidad en el genoma cloroplastidial?

### Visualización
Visualizamos nuestros alineamientos usando herramientas interactivas como IGV (Integrated Genome Viewer). Se puede encontrar para descargar [aquí](https://igv.org/doc/desktop/#DownloadPage). Este requiere de un sistema operativo con interfaz gráfica.

IGV funciona con una secuencia de referencia y uno o múltiples "tracks", que pueden ser alineamientos, genes, variantes, profundidades, etc. Los alineamientos y la secuencia de referencia deben ser indexados para cargarse a IGV
```bash
samtools index FIELD_LAM34.dedup.bam FIELD_LAM34.dedup.bam.bai
```
Copiar los archivos a su computadora local:
```bash
scp USERNAME@161.132.238.252:/home/USERNAME/3-mapeo_variantes/FIELD_LAM34.bam* .
scp USERNAME@161.132.238.252:/home/USERNAME/3-mapeo_variantes/FIELD_LAM34.bam.bai* .
scp USERNAME@161.132.238.252:/home/courses/course2026/course_files/ppa_v2.asm.fasta* .
```
En IGV, cambiar el genoma de referencia a ppa_v2.asm.fasta y luego cargar el archivo de alineamiento.

> [!IMPORTANT]
> :question: ¿Cómo se diferencian los mapeos de la muestra FIELD_LAM34 con los de HUSM_LAM25? ¿Cuáles son las posibles explicaciones?  
> :question: Realizar el mismo procedimiento para el genoma cloroplastidial. ¿Cuáles son las diferencias?

## 2. Estimación de genotipos y variantes
El llamado de variantes significa inferir sitios variantes a partir de los mapeos genómicos. Esto es preciso cuando se cuenta con una profundidad de secuenciación razonable para cada individuo. Para datos con poca profundidad, una alternativa consiste en la estimación de probabilidades de genotipo (_genotype likelihoods_), los cuales toman en cuenta la probabilidad de errores de secuenciación y mapeo, así como las características de mapeo de todos los individuos en la estimación de genotipos de una muestra. A partir de los genotipos se pueden estimar las probabilidades de frecuencias alélicas. Este análisis se incluye en el software _angsd_.

Usaremos un script para realizar este tipo de análisis con el software _angsd_, `4-genotipos.sh`.
```bash
cp /data/courses/course2026/course_files/scripts/4-genotipos.sh .
```
 En el contenido cambiar los USERNAME a los nombres de grupo:
```bash
#!/bin/bash

# Nombre del proceso:
#SBATCH --job-name=4-genotipos

# Proyecto:
#SBATCH --account=tipo-iii
#SBATCH --partition=standard # Nombre de la partición

# Recursos:
#SBATCH --time=24:00:00 # Límite de tiempo de corrida
#SBATCH --cpus-per-task=15 # Límite de CPUs para cada tarea en tareas de múltiples instancias
#SBATCH --mem=25G # Límite de memoria

# Archivos de salida
#SBATCH --output=/data/courses/course2026/USERNAME/logs/genotypes_o%j # Nombre del archivo de salida stdout
#SBATCH --error=/data/courses/course2026/USERNAME/logs/genotypes_e%j # Nombre del archivo de error stderr

# Ambiente de trabajo
set -o errexit
set -o nounset

module load angsd
module list

# Mensaje informativo
echo "Tarea ${SLURM_JOB_NAME} iniciado en:"
date
echo "Nodo:"
hostname

# Comandos a ejecutar
bam_list="bam_file.list"
ref_genome="/data/courses/course2026/course_files/mapeo_variantes/ppa_v2.asm.fasta"
prefix="HUSM_NORTH"

min_n=$(wc -l $bam_list | cut -d' ' -f1)
let min_n=$min_n/2

angsd -b $bam_list -GL 2 -doMajorMinor 1 -doGlf 2 -doPlink 2 \
-doPost 1 -doCounts 1 -nThreads 10 -SNP_pval 1e6 -doGeno -1 \
-doMaf 3 -minMapQ 30 -minQ 20 -minMaf 0.01 -doBcf 1 \
-geno_minDepth 2 -setMinDepthInd 2 -minInd $min_n -remove_bads 1 \
-uniqueOnly 1 -postCutoff 0.95 -baq 1 -C 50 -ref $ref_genome -out ${SLURM_JOB_ID}.$prefix

echo "Job finalizado en:"
date
```
Sometemos la tarea:
```bash
cp /data/courses/course2026/course_files/mapeo_variantes/bam_file.list .
sbatch 4-genotipos.sh
```

Las opciones de configuración pueden revisarse en el manual [aquí](https://www.popgen.dk/angsd/index.php/ANGSD). Entre estas se incluyen:
- **GL:** Método de estimación de probabilidad de genotipo. El 2 es GATK
- **doMajorMinor:** Inferir alelos mayor y menor. El 1 es basado en las probabilidades de genotipo.
- **doGlf:** Formato de salida de las probabilidades de genotipo. El 2 es el formato Beagle.
- **doPlink:** Registrar los genotipos en el formato de Plink.
- **doPost:** Estimar las probabilidades de genotipo en base a la frecuencia alélica como prior (1), en lugar de un prior uniforme (2).
- **doCounts:** Registra las frecuencias nucleotídicas.
- **nThreads:** Número de CPUs para el análisis.
- **SNP_pval:** Umbral en prueba de proporción de verosimilitudes para el filtrado posterior de SNPs.
- **doGeno:** Registrar las frecuencias genotípicas.
- **doMaf:** Estimar frecuencias alélicas.
- **minMapQ:** Valor mínimo de puntaje de calidad de mapeo.
- **minQ:** Valor mínimo de calidad de base.
- **minMaf:** Frecuencia alélica menor mínima.
- **geno_minDepth:** Mínimo de profundidad para la inferencia de genotipos por individuo.
- **setMinDepthInd:** Mínimo de profundidad de secuenciación para la inclusión de los datos de un individuo para un sitio.
- **minInd:** Mínimo de individuos con datos para estimar genotipos en un sitio.
- **remove_bads:** Remover lecturas con un valor FLAG por encima de 255.
- **uniqueOnly:** Remover lecturas mapeadas más de una vez.
- **postCutoff:** Mínimo de probabilidad posterior para genotipos.
- **baq:** Realizar computación baq
- **C:** Ajuste de mapQ para lecturas con varias diferencias.
- **ref:** Archivo del genoma de referencia.
- **out:** Prefijo de archivos de resultado

Entre varios de los archivos resultantes está el resumen de genotipos en formato Beagle. Este puede examinarse de la siguiente manera:
```bash
zcat HUSM_NORTH.beagle.gz | less -S
```
> [!IMPORTANT]
> :exclamation: Examinar los resultados en formato Plink y VCF, ¿Cuáles son las diferencias con respecto al archivo Beagle?
